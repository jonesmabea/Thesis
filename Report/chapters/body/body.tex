\let\textcircled=\pgftextcircled
\chapter{Methodology}
\label{chap:body}



\section{ Context Classification})
\subsection{Separation of data into urban and non urban Context}

The KITTI Dataset contains annotated labels for the objects in training and testing images and pointclouds. However this annotation does not include if the image is from an urban or non-urban context. 
In order to do so it was necessary to find a way to annotate the images and pointclouds in terms of urban or non-urban context. 

\subsection{Visual Classification}
 The first step was visual classification of the images into urban and non urban classes. 
 Depending on the  number of cars, vegetation, road 
-Segmentation using Deeplab 
extracting labelled regions 
Used to extract regions of interest 


\subsection{PointCloud classifier}


\subsubsection{Keypoint extraction }
Intrinsic Shape Signatures 

\subsubsection{Feature description}
Signature of Histogram of Orientations


\subsubsection{Matching}





Once the training dataset was classified into to the different contexts. I was able to train a classifier to determine the context of a pointcloud input. 





Conditional risk 


\subsubsection{Design}

\subsubsection{Evaluation}

Include pictures of results
	

\section{Context-Dependent Model Selection}
Introduction as to different modes of operation?
Multimodal vs Single model?
Modes of operation?

\subsubsection{VoxelNet }

\subsubsection{AVOD} 



\subsection{Conclusion}
Poor performance in terms of pedestrian and cyclists 
Good performance in non-urban areas 

\section{Validation with different datasets}


