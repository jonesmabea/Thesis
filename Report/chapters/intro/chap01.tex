% !TeX spellcheck = <engl>
%
% File: chap01.tex
% Author: Victor F. Brena-Medina
% Description: Introduction chapter where the biology goes.
%
\let\textcircled=\pgftextcircled
\chapter{Introduction}
\label{chap:intro}

Accelerated by recent advancements in technology, the prospect of Autonomous Vehicles (AVs) driving in public roads is becoming more and more a reality. As this is an emerging field, there are numerous variations of implementations by different companies. Arguably, a key characteristic of these implementations is a large number of perception sensors including cameras, radars and light and detection ranging sensors(LiDAR). This is necessary for perceiving the environment around the vehicles in order to safely maneuver around surrounding objects. However, most of these sensors are quite expensive and also energy inefficient thus making AVs unviable. In an effort to reduce the cost, companies are exploring different ways to reduce the number of sensors while still achieving a high level of navigational accuracy and safety.
 
In the multimodal approach, sensors are combined in various ways to achieve  cost effective yet accurate configurations. Common configurations include Camera only, camera and radar, camera, LiDAR and radar. This is influenced by the different stregnths and weaknesses of the sensors in terms of performance.  
Despite extensive research on these perception sensors, their performance  in urban and non-urban contexts has not been exhaustively explored. This presents an opportunity to redesign the sensor configurations from a top down approach by first understanding their performance in different contexts then designing models that are efficient and feasible.

In order to investigate the performance of these sensors, state of the art object detection models will be considered. Specifically, two models will be used as the templates in this evaluation. Firstly, VoxelNet \cite{zhou2017voxelnet}], is a LiDAR only  model that uses point clouds as input. Secondly, Aggregated View Object Detection(AVOD) \cite{ku2017joint} is multimodal model that fuses image and point cloud data. Both model implementations were available on GitHub and were heavily modified in order to align with the aims of this project. Nonetheless, they formed an essential foundation that cannot be understated. 

\section{Aims and Objectives}
Following the motivations in the presented discussion , the performance of LiDAR only and multimodal(LiDAR and Camera) models in different contexts will be investigated with the aim of reducing the number of sensors in AVs. 
To achieve this aim, the following objectives will need to be achieved.:
\begin{enumerate}
	\item Detect and characterise the context of images and point clouds.
	\item Evaluate the performance of sensors in different contexts. 
	\item Evaluate the performance of both models in different contexts. 
	\item Validate performance of single sensor model on custom dataset. 
	\item Legal, social and economic analysis of current implementations and proposed improvements. 
\end{enumerate}

\section{Deliverables}

The deliverables are split into two groups. 
\begin{itemize}
	 \item \textbf{Image and LiDAR Context Classifier}. Available as Jupyter interactive notebooks including pre-trained models.  
	 \item \textbf{Custom VoxelNet Model} Modified model of the VoxelNet unnoficial implementation including interactive notebooks for training, testing and validating the model. 
	 \item \textbf{Custom AVOD Model} Modified model of the AVOD oficial implementation including interactive notebooks for training, testing and validating the model.
	 \item \textbf{Validation Dataset} Point Cloud dataset obtained  from the .
	  
	\item \textbf{Evaluation report.} The following topics will be discussed. 
	\begin{enumerate}
		\item A review of related research and implementations tackling object detection using LiDAR cloud points. 
		\item Performance analysis of implementation and analysis criteria.
		\item A comparison between the implemented system and other state-of-the-art detection systems, potentially through a public benchmark. 
		\item The ethical and safety implications of the system and its viability in a real world setting. 
		\item Economic analysis of the implementation and its potential impact on the development of AVs. 
		\item Validation of implementation performance against university or public datasets containing data from AVs. 
	\end{enumerate}
\end{itemize}

\section{Report structure}

This report will consist of five main chapters. 
Chapter 2 discusses the different components of AVs, current implementations in the industry, a background on the research that has been undertaken in the field of object detection and finally a brief overview of deep learning frameworks. 

Chapter 3 is the final discussion that forms the conclusion of the review. In this chapter, I will evaluate what I hope to achieve and the assumptions and hypotheses that I have formulated. 


