{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Dataset Notebook\n",
    "## Customised to use VoxelNet trained Graphs on custom datasets.\n",
    "## Please use the csvToKITTI utility tool to convert VeloView CSVs to a compatible output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "# from comet_ml import Experiment\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from model import RPN3D\n",
    "from config import cfg\n",
    "from utils import *\n",
    "from utils.kitti_loader import iterate_data, sample_test_data,GPULogging\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx = 'non_urban' \n",
    "tag = 'default_pedestrian'\n",
    "data_dir='/mnt/storage/home/ja17618/scratch/'\n",
    "output_path = data_dir+'/out/' \n",
    "bs=1\n",
    "vis=True\n",
    "GPU_AVAILABLE='0'\n",
    "GPU_USE_COUNT=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/storage/home/ja17618/.conda/envs/vox/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from config import cfg\n",
    "from utils.data_aug import aug_data\n",
    "from utils.preprocess import process_pointcloud\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, data_tag, f_lidar, data_dir, aug, is_testset):\n",
    "        self.data_tag=data_tag\n",
    "        self.f_lidar = f_lidar\n",
    "        self.data_dir = data_dir\n",
    "        self.aug = aug\n",
    "        self.is_testset = is_testset\n",
    "    \n",
    "    def __call__(self,load_index):\n",
    "        if self.aug:\n",
    "            ret = aug_data(self.data_tag[load_index], self.data_dir)\n",
    "        else:\n",
    "            raw_lidar = np.fromfile(self.f_lidar[load_index], dtype=np.float32).reshape((-1, 4))\n",
    "            if not self.is_testset:\n",
    "                labels = [line for line in open(self.f_label[load_index], 'r').readlines()]\n",
    "            else:\n",
    "                labels = ['']\n",
    "            tag = self.data_tag[load_index]\n",
    "            voxel = process_pointcloud(raw_lidar)\n",
    "            ret = [tag, raw_lidar, voxel, labels]\n",
    "        return ret\n",
    "\n",
    "# global pool\n",
    "TRAIN_POOL = multiprocessing.Pool(4)\n",
    "VAL_POOL = multiprocessing.Pool(2)\n",
    "\n",
    "def iterate_val_data(data_dir, shuffle=False, aug=False, is_testset=True, batch_size=1, multi_gpu_sum=1):\n",
    "    f_lidar = glob.glob(os.path.join(data_dir, 'output', '*.bin'))\n",
    "    f_lidar.sort()\n",
    "    \n",
    "    data_tag = [name.split('/')[-1].split('.')[-2] for name in f_lidar]\n",
    "      \n",
    "    nums = len(f_lidar)\n",
    "    indices = list(range(nums))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    num_batches = int(math.floor( nums / float(batch_size) ))\n",
    "\n",
    "    proc=Processor(data_tag, f_lidar, data_dir, aug, is_testset)\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        \n",
    "        rets=TRAIN_POOL.map(proc,excerpt)\n",
    "\n",
    "        tag = [ ret[0] for ret in rets ]\n",
    "        raw_lidar = [ ret[1] for ret in rets ]\n",
    "        voxel = [ ret[2] for ret in rets ]\n",
    "        labels = [ ret[3] for ret in rets ]\n",
    "\n",
    "        # only for voxel -> [gpu, k_single_batch, ...]\n",
    "        vox_feature, vox_number, vox_coordinate = [], [], []\n",
    "        single_batch_size = int(batch_size / multi_gpu_sum)\n",
    "        for idx in range(multi_gpu_sum):\n",
    "            _, per_vox_feature, per_vox_number, per_vox_coordinate = build_input(voxel[idx * single_batch_size:(idx + 1) * single_batch_size])\n",
    "            vox_feature.append(per_vox_feature)\n",
    "            vox_number.append(per_vox_number)\n",
    "            vox_coordinate.append(per_vox_coordinate)\n",
    "\n",
    "        ret = (\n",
    "               np.array(tag),\n",
    "               np.array(labels),\n",
    "               np.array(vox_feature),\n",
    "               np.array(vox_number),\n",
    "               np.array(vox_coordinate),\n",
    "               np.array(raw_lidar)\n",
    "               )\n",
    "\n",
    "        yield ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = open('/mnt/storage/home/ja17618/vox_nurbgpu3.out','w+')\n",
    "# log.flush()\n",
    "\n",
    "dataset_dir =data_dir\n",
    "# val_dir = os.path.join(cfg.CONTEXT_DIR, ctx)\n",
    "save_model_dir = os.path.join('./save_model', tag)\n",
    "total_inference_time = []\n",
    "\n",
    "# experiment = Experiment(api_key=\"xXtJguCo8yFdU7dpjEpo6YbHw\",project_name=exp)\n",
    "# create output folder\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_path, 'data'), exist_ok=True)\n",
    "\n",
    "if vis:\n",
    "    os.makedirs(os.path.join(output_path, 'vis'), exist_ok=True)\n",
    "# process = subprocess.Popen('nvidia-smi -i 1 --format=csv -l 1 --query-gpu=index,timestamp,power.draw,utilization.gpu,clocks.current.sm,temperature.gpu,memory.used',stdout = log, shell=True)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=cfg.GPU_MEMORY_FRACTION,\n",
    "                        visible_device_list=GPU_AVAILABLE,\n",
    "                        allow_growth=True)\n",
    "\n",
    "    config = tf.ConfigProto(\n",
    "        gpu_options=gpu_options,\n",
    "        device_count={\n",
    "            \"GPU\": GPU_USE_COUNT,\n",
    "        },\n",
    "        allow_soft_placement=True,\n",
    "        log_device_placement=False\n",
    "    )\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = RPN3D(\n",
    "            cls=cfg.DETECT_OBJ,\n",
    "            single_batch_size=bs,\n",
    "            avail_gpus=GPU_AVAILABLE\n",
    "        )\n",
    "        if tf.train.get_checkpoint_state(save_model_dir):\n",
    "            print(\"Reading model parameters from %s\" % save_model_dir)\n",
    "            model.saver.restore(\n",
    "                sess, tf.train.latest_checkpoint(save_model_dir))\n",
    "        counter=0\n",
    "#         with experiment.test():\n",
    "        for batch in iterate_val_data(dataset_dir, shuffle=False, aug=False, is_testset=True, batch_size=bs * GPU_USE_COUNT, multi_gpu_sum=GPU_USE_COUNT):\n",
    "#             experiment.log_metric(\"counter\",counter)\n",
    "            tf.profiler.profile(\n",
    "                options=tf.profiler.ProfileOptionBuilder.float_operation(),run_meta=run_metadata)\n",
    "            if vis:\n",
    "                tags, results, bird_views, heatmaps = model.predict_velo_step(sess, batch, vis=True)\n",
    "            else:\n",
    "                inference_start_time=time.time()\n",
    "                tags, results = model.predict_velo_step(sess, batch, vis=False)\n",
    "                inference_time = time.time()-inference_start_time\n",
    "                total_inference_time.append(inference_time)\n",
    "\n",
    "            # ret: A, B\n",
    "            # A: (N) tag\n",
    "            # B: (N, N') (class, x, y, z, h, w, l, rz, score)\n",
    "            for tag, result in zip(tags, results):\n",
    "                of_path = os.path.join(output_path, 'data', tag + '.txt')\n",
    "                with open(of_path, 'w+') as f:\n",
    "                    labels = box3d_to_label([result[:, 1:8]], [result[:, 0]], [result[:, -1]], coordinate='lidar')[0]\n",
    "                    for line in labels:\n",
    "                        f.write(line)\n",
    "                    if len(labels)>0:\n",
    "                        print('write out {} objects to {}'.format(len(labels), tag))\n",
    "            # dump visualizations\n",
    "            if vis:\n",
    "                for tag, bird_view, heatmap in zip(tags, bird_views, heatmaps):\n",
    "#                     front_img_path = os.path.join( output_path, 'vis', tag + '_front.jpg'  )\n",
    "                    bird_view_path = os.path.join( output_path, 'vis', tag + '_bv.jpg'  )\n",
    "                    heatmap_path = os.path.join( output_path, 'vis', tag + '_heatmap.jpg'  )\n",
    "#                     cv2.imwrite( front_img_path, front_image )\n",
    "                    print(bird_view_path)\n",
    "                    cv2.imwrite( bird_view_path, bird_view )\n",
    "                    cv2.imwrite( heatmap_path, heatmap )\n",
    "            counter +=1\n",
    "# process.kill()\n",
    "# log.flush()\n",
    "# log.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_inference = np.mean(total_inference_time)\n",
    "min_inference = np.min(total_inference_time)\n",
    "max_inference =np.max(total_inference_time)\n",
    "var_inference = np.var(total_inference_time)\n",
    "\n",
    "print('Min: %fs Max: %fs Mean: %fs Var: %fs ' %( min_inference,max_inference,mean_inference,var_inference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
